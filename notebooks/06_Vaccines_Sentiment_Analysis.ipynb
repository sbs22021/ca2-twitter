{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a3d2c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35a40581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import tweetnlp\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.types import IntegerType, StringType, StructType, StructField, DoubleType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pymongo import MongoClient\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f22a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_uri = \"mongodb://hadoop-vm.internal.cloudapp.net:27017/ca2\"\n",
    "\n",
    "# Spark version 3.2.3\n",
    "# MongoDB version 6.0.5\n",
    "# Java Version 11\n",
    "\n",
    "# create a spark session\n",
    "# Jars dependencies available in maven repository\n",
    "# https://mvnrepository.com/search?q=mongodb-driver-sync\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('Tweets') \\\n",
    "    .config(\"spark.mongodb.read.connection.uri\", mongo_uri) \\\n",
    "    .config(\"spark.mongodb.write.connection.uri\", mongo_uri) \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:10.1.1\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb:mongodb-driver-core:4.9.1\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb:mongodb-driver-sync:4.9.1\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb:bson:4.9.1\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c36a8ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from mongodb collection \"tweets\" into a dataframe \"df\"\n",
    "df = spark.read \\\n",
    "    .format(\"mongodb\") \\\n",
    "    .option(\"connection.uri\", mongo_uri) \\\n",
    "    .option(\"database\", \"ca2\") \\\n",
    "    .option(\"collection\", \"vaccin_tweets_2\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c010bf1",
   "metadata": {},
   "source": [
    "# Sentiment analysis with pretrained model \n",
    "\n",
    "https://aclanthology.org/2020.findings-emnlp.148\n",
    "\n",
    "https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d7f5d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tweetnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11e22fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = tweetnlp.Sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1824cd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess tweets to remove user info and any web url as Roberta \n",
    "def parse_tweet(tweet):\n",
    "    new_text = []\n",
    "    for t in tweet.split(\" \"):\n",
    "        t = \"@user\" if t.startswith(\"@\") and len(t) > 1 else t\n",
    "        t = \"http\" if t.startswith(\"http\") else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "# generate sentiment scores\n",
    "def sentiment_analyzer(text, model):\n",
    "    output = model.sentiment(text, return_probability=True)\n",
    "    return (output['label'], output['probability'][output['label']])\n",
    "\n",
    "def process_data(df, start_index, end_index, skip_to=0):\n",
    "    total_count = df_pd['_id'].count()\n",
    "    num_batches = (total_count // batch_size) + 1\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        if(start < skip_to):\n",
    "            continue\n",
    "        \n",
    "        print(f\"processing from {start} to {end}...\")\n",
    "        # Select the batch of data\n",
    "        batch_df = df[(df['index'] >= start) & (df['index'] < end)]\n",
    "        \n",
    "        # Apply the sentiment function to 'text' column\n",
    "        batch_df['sentiment'], batch_df['s_probability'] = zip(*batch_df['text'].progress_apply(lambda x: sentiment_analyzer(x,model)))\n",
    "        \n",
    "        # Convert the pandas DataFrame to a list of dictionaries\n",
    "        data_to_insert = batch_df[['_id','sentiment','s_probability']].to_dict('records')\n",
    "\n",
    "        # Insert data into MongoDB\n",
    "        collection.insert_many(data_to_insert)\n",
    "        print(f\"processed {end} of {total_count} - {round((end / total_count)):.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6d3f1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tweets in memory\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading tweets in memory\")\n",
    "df_pd = df.toPandas()\n",
    "df_pd = df_pd[['_id','text']]\n",
    "df_pd['text'] = df_pd['text'].apply(lambda x: parse_tweet(x))\n",
    "\n",
    "# Add index to your dataframe\n",
    "df_pd['index'] = df_pd.index\n",
    "\n",
    "\n",
    "# Start client connection to mongo\n",
    "client = MongoClient(mongo_uri)\n",
    "db = client[\"ca2\"]\n",
    "collection = db[\"vaccin_tweets_2_sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5549f9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch process\n",
    "batch_size = 2000\n",
    "start_index = 0\n",
    "end_index = df_pd['index'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcc419c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting process_data\n",
      "processing from 292000 to 294000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [02:35<00:00, 12.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 294000 of 317631 - 100.00%\n",
      "processing from 294000 to 296000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [02:50<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 296000 of 317631 - 100.00%\n",
      "processing from 296000 to 298000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [02:47<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 298000 of 317631 - 100.00%\n",
      "processing from 298000 to 300000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [02:43<00:00, 12.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 300000 of 317631 - 100.00%\n",
      "processing from 300000 to 302000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [02:44<00:00, 12.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 302000 of 317631 - 100.00%\n",
      "processing from 302000 to 304000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [02:44<00:00, 12.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 304000 of 317631 - 100.00%\n",
      "processing from 304000 to 306000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [02:46<00:00, 12.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 306000 of 317631 - 100.00%\n",
      "processing from 306000 to 308000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [02:44<00:00, 12.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 308000 of 317631 - 100.00%\n",
      "processing from 308000 to 310000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [02:39<00:00, 12.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 310000 of 317631 - 100.00%\n",
      "processing from 310000 to 312000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [03:08<00:00, 10.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 312000 of 317631 - 100.00%\n",
      "processing from 312000 to 314000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [02:57<00:00, 11.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 314000 of 317631 - 100.00%\n",
      "processing from 314000 to 316000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [02:56<00:00, 11.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 316000 of 317631 - 100.00%\n",
      "processing from 316000 to 318000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1631/1631 [02:27<00:00, 11.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 318000 of 317631 - 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Starting process_data\")\n",
    "process_data(df_pd,start_index,end_index,skip_to=292000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89dcdf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****End******\n"
     ]
    }
   ],
   "source": [
    "print(f\"*****End******\")\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702a57f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
