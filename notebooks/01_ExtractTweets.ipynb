{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f0b6e50c-9256-45bb-a51d-83a8d705b219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "hdfs_directory = 'hdfs://hadoop-vm.internal.cloudapp.net:9000/twitter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1181246-53bd-49ed-b49a-36e9c687815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95747c56-684c-4f32-9951-8392cf19bf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import tarfile\n",
    "import bz2\n",
    "import json\n",
    "from hdfs import InsecureClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1503b89a-e29c-4417-a1bf-3cb5b675645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['COVID-19', 'Coronavirus', 'Pandemic', 'Vaccine', 'Vaccination', 'Immunization', 'COVID vaccine', 'Vaccine rollout', 'Vaccine hesitancy', 'Vaccine mandate', 'Booster shot', 'Vaccine passport', 'Vaccination rate', 'Public health', 'WHO', 'CDC']\n",
    "hashtags = ['#COVID19', '#Coronavirus', '#Pandemic', '#Vaccine', '#Vaccination', '#GetVaccinated', '#COVIDVaccine', '#Immunization', '#VaccineHesitancy', '#VaccineMandate', '#BoosterShot', '#VaccinePassport', '#PublicHealth', '#StaySafe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20dc3ca1-e898-40cf-b1cf-dbe81ee7f17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tar_file(file_path, destination_folder):\n",
    "    with tarfile.open(file_path, 'r') as tar:\n",
    "        tar.extractall(path=destination_folder)\n",
    "        \n",
    "def extract_bz2_file(file_path, destination_folder):\n",
    "    with bz2.open(file_path, 'rt') as f_in:\n",
    "        file_name = os.path.basename(file_path).replace('.bz2', '')\n",
    "        extracted_file_path = os.path.join(destination_folder, file_name)\n",
    "        \n",
    "        with open(extracted_file_path, 'w') as f_out:\n",
    "            f_out.write(f_in.read())\n",
    "            \n",
    "    return extracted_file_path\n",
    "\n",
    "def get_all_files(directory):\n",
    "    file_list = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_list.append(os.path.join(root, file))\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "611eb373-fd6b-4d80-a9dc-0fa77360f454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change directory to dowload folder\n",
    "output_directory = \"data\"\n",
    "os.chdir(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56c99df-6c74-407b-ba49-9859e2a76920",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in [2020,2021]:\n",
    "    for month in range(1, 13):\n",
    "        # skiping february 2020. This is covid outbreak news and it's almost 1TB of compressed files\n",
    "        if((month == 2) & (year == 2020))\n",
    "            continue\n",
    "        for day in range(1, 32):\n",
    "            try:\n",
    "                file_path = download_twitter_data(year, month, day)\n",
    "                extracted_data_directory = f\"{year}/{str(month).zfill(2)}\"\n",
    "\n",
    "                if not os.path.exists(extracted_data_directory):\n",
    "                    os.makedirs(extracted_data_directory)\n",
    "\n",
    "                if os.path.exists(file_path):\n",
    "                    # Extract .tar file\n",
    "                    extract_tar_file(file_path, extracted_data_directory)\n",
    "\n",
    "                output_file = f\"covid-{year}-{str(month).zfill(2)}.json\"\n",
    "                with open(output_file, 'w') as f_out:\n",
    "                    # Extract .bz2\n",
    "                    for bz2_file_path in get_all_files(extracted_data_directory):\n",
    "                        if bz2_file_path.endswith('.bz2'):\n",
    "                            extracted_file_path = extract_bz2_file(bz2_file_path, extracted_data_directory)\n",
    "                            # Read the file\n",
    "                            with open(extracted_file_path, 'r') as f_in:\n",
    "                                for line in f_in:\n",
    "                                    tweet = json.loads(line)\n",
    "                                    try:\n",
    "                                        # Check if tweet contains a keyword or hashtag\n",
    "                                        if any(keyword in tweet['text'] for keyword in keywords) or any(hashtag in tweet['text'] for hashtag in hashtags):\n",
    "                                            json.dump(tweet, f_out)\n",
    "                                            f_out.write('\\n')\n",
    "                                    except:\n",
    "                                        _\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading data for {year}-{month}-{day}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09299b01-e88f-46cf-b62b-67639c8ce635",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2020\n",
    "for month in range(1, 13):\n",
    "    for day in range(1, 32):\n",
    "        try:\n",
    "            file_path = download_twitter_data(year, month, day)\n",
    "            extracted_data_directory = f\"{year}/{str(month).zfill(2)}\"\n",
    "            \n",
    "            if not os.path.exists(extracted_data_directory):\n",
    "                os.makedirs(extracted_data_directory)\n",
    "\n",
    "            if os.path.exists(file_path):\n",
    "                # Extract .tar file\n",
    "                extract_tar_file(file_path, extracted_data_directory)\n",
    "\n",
    "            output_file = f\"covid-{year}-{str(month).zfill(2)}.json\"\n",
    "            with open(output_file, 'w') as f_out:\n",
    "                # Extract .bz2\n",
    "                for bz2_file_path in get_all_files(extracted_data_directory):\n",
    "                    if bz2_file_path.endswith('.bz2'):\n",
    "                        extracted_file_path = extract_bz2_file(bz2_file_path, extracted_data_directory)\n",
    "                        # Read the file\n",
    "                        with open(extracted_file_path, 'r') as f_in:\n",
    "                            for line in f_in:\n",
    "                                tweet = json.loads(line)\n",
    "                                try:\n",
    "                                    # Check if tweet contains a keyword or hashtag\n",
    "                                    if any(keyword in tweet['text'] for keyword in keywords) or any(hashtag in tweet['text'] for hashtag in hashtags):\n",
    "                                        json.dump(tweet, f_out)\n",
    "                                        f_out.write('\\n')\n",
    "                                except:\n",
    "                                    _\n",
    "                        # Remove extracted files after uploading\n",
    "                        os.remove(extracted_file_path)\n",
    "                        os.remove(bz2_file_path)\n",
    "                \n",
    "                # Remove year folder\n",
    "                os.remove(year)\n",
    "                \n",
    "                # Remove tar file\n",
    "                os.remove(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading data for {year}-{month}-{day}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - Spark (local)",
   "language": "python",
   "name": "spark-3-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
